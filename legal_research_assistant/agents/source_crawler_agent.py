from tavily import TavilyClient

class SourceCrawlerAgent:
    """
    A class to search for relevant legal sources based on keywords using Tavily API.
    """
    def __init__(self, api_key: str):
        """
        Initializes the agent with the Tavily API key.

        Args:
            api_key: The Tavily API key.
        """
        if not api_key or "YOUR_TAVILY_KEY_HERE" in api_key:
            # TODO: Replace print with logging for better production error handling
            print("Warning: Tavily API key is missing or a placeholder. SourceCrawlerAgent may not function.")
            self.tavily_client = None
        else:
            self.tavily_client = TavilyClient(api_key=api_key)

    def search_ssrn(self, keywords: list, max_results_per_keyword: int = 3) -> list:
        """
        Searches SSRN (via Tavily) for relevant sources based on keywords.

        Args:
            keywords: A list of keywords generated by the KeywordGeneratorAgent.
            max_results_per_keyword: Maximum number of results to fetch for each keyword.

        Returns:
            A list of found articles (dictionaries with title, url, abstract, source).
        """
        if not self.tavily_client:
            print("Tavily client not initialized due to missing API key. Cannot search.")
            return []
        
        if not keywords:
            print("No keywords provided for searching.")
            return []

        all_found_articles = []
        for keyword in keywords:
            query = f'{keyword} site:papers.ssrn.com OR site:ssrn.com'
            print(f"   - Searching SSRN (via Tavily) for: \"{query}\"")
            try:
                # Use search_depth="basic" for speed, "advanced" for more detail if needed.
                # Tavily's max_results is more of a guideline, actual results can vary.
                response = self.tavily_client.search(
                    query=query,
                    search_depth="basic", # "advanced" can be used for more detailed context
                    max_results=max_results_per_keyword,
                    # include_domains=["papers.ssrn.com", "ssrn.com"] # Optional: further restrict domains
                )
                
                results = response.get('results', [])
                for result in results:
                    # Ensure the URL is indeed from SSRN if Tavily returns broader results
                    if 'ssrn.com' in result.get('url', ''):
                        article = {
                            'title': result.get('title', 'N/A'),
                            'url': result.get('url', 'N/A'),
                            # 'content' from Tavily is usually a good snippet/abstract
                            'abstract': result.get('content', 'N/A'), 
                            'score': result.get('score', 0.0), # Tavily provides a relevance score
                            'source': 'SSRN (via Tavily)'
                        }
                        all_found_articles.append(article)
            except Exception as e:
                # TODO: Replace print with logging and consider more specific exceptions
                print(f"   - Error searching with Tavily for keyword '{keyword}': {e}")
        
        # Deduplicate results based on URL (keeping the first encountered version)
        seen_urls = set()
        unique_articles = []
        for article in all_found_articles:
            if article['url'] not in seen_urls:
                unique_articles.append(article)
                seen_urls.add(article['url'])
        
        return unique_articles

    def search_jstor(self, keywords: list, max_results_per_keyword: int = 3) -> list:
        """
        Searches JSTOR (via Tavily) for relevant sources based on keywords.

        Args:
            keywords: A list of keywords generated by the KeywordGeneratorAgent.
            max_results_per_keyword: Maximum number of results to fetch for each keyword.

        Returns:
            A list of found articles (dictionaries with title, url, abstract, source).
        """
        if not self.tavily_client:
            print("Tavily client not initialized due to missing API key. Cannot search JSTOR.")
            return []
        
        if not keywords:
            print("No keywords provided for searching JSTOR.")
            return []

        all_found_articles = []
        for keyword in keywords:
            query = f'{keyword} site:jstor.org'
            print(f"   - Searching JSTOR (via Tavily) for: \"{query}\"")
            try:
                response = self.tavily_client.search(
                    query=query,
                    search_depth="basic",
                    max_results=max_results_per_keyword,
                    # include_domains=["www.jstor.org"] # Optional
                )
                
                results = response.get('results', [])
                for result in results:
                    if 'jstor.org' in result.get('url', ''):
                        article = {
                            'title': result.get('title', 'N/A'),
                            'url': result.get('url', 'N/A'),
                            'abstract': result.get('content', 'N/A'), 
                            'score': result.get('score', 0.0),
                            'source': 'JSTOR (via Tavily)'
                        }
                        all_found_articles.append(article)
            except Exception as e:
                # TODO: Replace print with logging and consider more specific exceptions
                print(f"   - Error searching JSTOR with Tavily for keyword '{keyword}': {e}")
        
        seen_urls = set()
        unique_articles = []
        for article in all_found_articles:
            if article['url'] not in seen_urls:
                unique_articles.append(article)
                seen_urls.add(article['url'])
        
        return unique_articles

    # Retain the old search_sources method, but mark it as deprecated or point to search_ssrn
    def search_sources(self, keywords: list) -> list:
        """
        DEPRECATED: Please use search_ssrn and search_jstor directly.
        This method is a placeholder and will be removed or updated.
        If called, it currently only searches SSRN.
        """
        print("Warning: `search_sources` is deprecated. It currently only calls `search_ssrn`.")
        print("         Consider calling `search_ssrn` and `search_jstor` methods directly from main.")
        return self.search_ssrn(keywords)
